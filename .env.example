# Server configuration
HOST=0.0.0.0
PORT=8000
DEBUG=False
MAX_CONCURRENT_USERS=3
MODEL_POOL_SIZE=MAX_CONCURRENT_USERS
QUEUE_TIMEOUT=300
REQUEST_TIMEOUT=120

# LLM configuration
CURRENT_LLM=https://huggingface.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/Qwen2.5-1.5B-Instruct-Q4_K_M.gguf
NUM_THREADS=1
TEMPERATURE=0.2

# Embedding configuration
CURRENT_EMBED=BAAI/bge-m3

# Logging
LOG_LEVEL=INFO
